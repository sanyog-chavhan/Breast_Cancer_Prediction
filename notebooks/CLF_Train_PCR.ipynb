{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c82e2f",
   "metadata": {},
   "source": [
    "## Importing Libraries and load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir()\n",
    "data = pd.read_excel('TrainDataset2023.xls')\n",
    "cols = data.columns.values\n",
    "\n",
    "# Checking for improper column names\n",
    "bad_names = [name for name in cols if re.findall(r\"\\W\",name)]\n",
    "repaired_names = [re.sub(r'\\s|\\(.+\\)','',name) for name in cols]\n",
    "\n",
    "\n",
    "# Rename columns\n",
    "data.columns = repaired_names\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c331da",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicated rows\n",
    "# No duplicates were found in data\n",
    "duplicates = data.duplicated()\n",
    "# duplicates[duplicates==True]\n",
    "duplicates.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "# Missing values are coded as 999\n",
    "\n",
    "for col in data.columns:\n",
    "    data[col].replace(999,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(df):\n",
    "    missing = df.isna().sum()\n",
    "    missing = missing[missing>0]\n",
    "    missing.sort_values(ascending=False,inplace=True)\n",
    "    # print(missing)\n",
    "    return(missing)\n",
    "\n",
    "check_missing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e40e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the target is outcome of treatment, imputing this variable may not be safe, therefore dropped from the dataset\n",
    "# missing values in features can be imputed\n",
    "data = data.loc[~data['pCR'].isna(),:]\n",
    "\n",
    "# again check for missing values\n",
    "check_missing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f170d",
   "metadata": {},
   "source": [
    "# Checking unique values for each column\n",
    "- This basically identifies categorical features in data, since no text labels were provided\n",
    "- experiment with different thresholds to confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdefaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_uni = dict()\n",
    "for i,col in enumerate(data.columns.values):\n",
    "    count_uni[col] = len(np.unique(data.loc[:,col]))\n",
    "\n",
    "# print(count_uni)\n",
    "\n",
    "list_cat = []\n",
    "for key,val in count_uni.items():\n",
    "    if count_uni[key]<10:\n",
    "        list_cat.append(key)\n",
    "        # print(f\"{key}:{val}\")\n",
    "\n",
    "print(f\"There are : {len(list_cat)} categotical fetures: {list_cat}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ID column\n",
    "# data.drop('ID',axis=1,inplace=True)\n",
    "# data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c71e9",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "- Dataset is unbalanced, around 78 percent are negative samples for `pCR`. Therefore it is necessary that train-test split produce represenative sets \n",
    "- Train test split is done before even exploring the dataset! to ensure that the test set is unseen to avoid so called data snooping bias. Notewortthy, seeing full dataset before training may influence choice of particular algorithm, thus prone to overfitting to data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bdacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the dataset into training and test sets, before pre-processing to avoid data leakage\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# For classification task\n",
    "data_train, data_test = train_test_split(data,test_size=.20,shuffle=True,stratify=data['pCR'],random_state=0)\n",
    "\n",
    "print(data_train.index)\n",
    "# Lets rename our training data as df to avoid any confusion in subsequent stages\n",
    "# From now nowards the training set will be df, and we have reserved `data_test` for evaluation\n",
    "# df will be used for exploratory analysis only\n",
    "df = data_train.copy()\n",
    "df.drop('ID',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b5c52c",
   "metadata": {},
   "source": [
    "## EXPORT TEST DATA IN PRESCRIBED FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaaa3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_export = data_test.loc[:,~data_test.columns.isin(['pCR','RelapseFreeSurvival'])]\n",
    "test_set_export.to_excel('test_set_PCR.xlsx',index=False)\n",
    "test_set_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb714d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution (proportions of positive vs negative samples) of data by pCR\n",
    "p_df = df['pCR'].value_counts()/sum(df['pCR'].value_counts())\n",
    "p_test = data_test['pCR'].value_counts()/sum(data_test['pCR'].value_counts())\n",
    "\n",
    "print(p_df)\n",
    "print(df.shape)\n",
    "print(p_test)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d73e7e",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "- KNN imputer is preferred since it imputes values based on closely similar datapoints\n",
    "- One neigbor is used for imputation, this avoids meaningless imputation for categorical features\n",
    "- To avoid data leakage, a test set is reserved before any data preprocessing\n",
    "- This will be used to evaluate the models after training is completed\n",
    "- imputation done here is just for exploratoty analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values by imputation, \n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "\n",
    "try:\n",
    "    tmp = imputer.fit_transform(df)\n",
    "except KeyError:\n",
    "    print('Variable not found')\n",
    "\n",
    "imputer.feature_names_in_\n",
    "imputer.n_features_in_\n",
    "\n",
    "df_imp = pd.DataFrame(tmp,columns=imputer.get_feature_names_out())\n",
    "# X_train.head()\n",
    "\n",
    "print(df_imp.shape)\n",
    "print(df.shape)\n",
    "\n",
    "# check missing\n",
    "check_missing(df_imp)\n",
    "\n",
    "# df_imp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f423396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe continuous features\n",
    "df_imp.loc[:,~df_imp.columns.isin(list_cat+['RelapseFreeSurvival'])].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts for target `pCR`and categorical features\n",
    "\n",
    "for v in list_cat:\n",
    "    print(df_imp[v].value_counts())\n",
    "\n",
    "#data['pCR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change categorical features to int for better hist plots\n",
    "# data_cat = df_imp[list_cat]\n",
    "# data_types =  data_cat.dtypes\n",
    "\n",
    "# for feature in list_cat:\n",
    "#     # if data_cat[feature].dtype!=object:\n",
    "#     data_cat.loc[:,feature] = data_cat[feature].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change categorical features to int for better hist plots\n",
    "data_cat = df_imp[list_cat]\n",
    "data_types =  data_cat.dtypes\n",
    "\n",
    "for feature in list_cat:\n",
    "    # if data_cat[feature].dtype!=object:\n",
    "    data_cat.loc[:,feature] = data_cat[feature].astype('int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9dd64b",
   "metadata": {},
   "source": [
    "## Categorical features vs `pCR`\n",
    "- There are observed differences in counts between negative and positive samples for pGR, HistrologyType, TumorStage, etc..\n",
    "- To be confirmed later by statistical tests, to ensure the observed differences are not by chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(5,2,figsize=(10,20))\n",
    "for ax, series in zip(axs.ravel(),data_cat):\n",
    "    sns.countplot(x=series,ax=ax, data=data_cat,hue='pCR')\n",
    "# axs[0,0].set_title('ER')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7ad73",
   "metadata": {},
   "source": [
    "## Visualizing continuous data\n",
    "- so many features have outliers, these need be removed\n",
    "- some are so huge, potentially indicating data entry errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9309af",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cont = [i for i in df_imp.columns.values if i not in list_cat]\n",
    "data_cont = df_imp.loc[:,list_cont]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(10,11,figsize=(100,60))\n",
    "for ax, series in zip(axs.ravel(),data_cont):\n",
    "    sns.boxplot(x=series,ax=ax, data=data_cont)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(8,8,figsize=(25,20))\n",
    "axs = axs.ravel()\n",
    "for i,col in enumerate(data_cont.iloc[:,0:64].columns.values):\n",
    "    axs[i].hist(x=col,bins=50,data=data_cont.iloc[:,0:64])\n",
    "    axs[i].set_title(col)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6068d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d14d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cont.iloc[:,64:data_cont.shape[1]].hist(bins=50,figsize=(30,25))\n",
    "fig, axs = plt.subplots(8,6,figsize=(25,20))\n",
    "axs = axs.ravel()\n",
    "for i,col in enumerate(data_cont.iloc[:,64:].columns.values):\n",
    "    axs[i].hist(x=col,bins=50,data=data_cont.iloc[:,64:])\n",
    "    axs[i].set_title(col)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairs plots\n",
    "# add pcr to color pairs plots to check more clearly\n",
    "list_cont_pcr = list_cont[:]\n",
    "list_cont_pcr.pop(list_cont_pcr.index('RelapseFreeSurvival'))\n",
    "list_cont_pcr.insert(0,'pCR')\n",
    "df.loc[:,list_cont_pcr]\n",
    "\n",
    "sns.pairplot(data=df.loc[:,list_cont_pcr[0:11]],hue='pCR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b88e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = list_cont_pcr[11:21]\n",
    "l2.insert(0,'pCR')\n",
    "sns.pairplot(data=df.loc[:,l2],hue='pCR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abb4b4",
   "metadata": {},
   "source": [
    "## Comparing feature ranges\n",
    " - Huge difference between feature ranges, normalization necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax=plt.subplots(1,figsize=(40,8))\n",
    "sns.boxplot(data=df.iloc[:,1:50],ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ed3cd",
   "metadata": {},
   "source": [
    "## Removing outliers\n",
    "- Identify them by using factor 1.5*IQR, \n",
    "Ref: Brownlee, J., 2020. Data preparation for machine learning: data cleaning, feature selection, and data transforms in Python. Machine Learning Mastery.\n",
    "- lets replace them with median values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c60ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemover:\n",
    "    \"\"\"\n",
    "    Takes `dataframe` as an input and list of continuous features in data frame 'cont_features_list'\n",
    "    to get a list of features with outliers pass `.features_with_outliers` attribute to OutlierRemover object instance\n",
    "    \"\"\"\n",
    "    def __init__(self,dataframe,cont_features_list):\n",
    "        self.dataframe = dataframe\n",
    "        self.cont_features_list = cont_features_list\n",
    "\n",
    "\n",
    "    def transform(self,factor=3):\n",
    "        \"\"\"\n",
    "        Factor is a multiplying factor to the interquartile range (IQR), cutoff = factor*IQR. Default is 3 for extreme outliers, 1.5 can be used.\n",
    "        An outlier is identified as feature value that is larger than 3rd quatile + cutoff or less 1st quartile - cutoff value.\n",
    "        \"\"\"\n",
    "        data_cont = self.dataframe.loc[:,self.dataframe.columns.isin(self.cont_features_list)]\n",
    "        p25, p50, p75 = np.nanquantile(data_cont,.25,axis=0),np.nanquantile(data_cont,.5,axis=0),np.nanquantile(data_cont,.75,axis=0)\n",
    "\n",
    "        cutoff = factor*(p75-p25) \n",
    "        lower, upper = p25 - cutoff, p75 + cutoff\n",
    "\n",
    "        dict_upper = dict()\n",
    "        dict_lower = dict()\n",
    "        dict_med = dict()\n",
    "        for low, up, med,col in zip(lower,upper,p50,data_cont.columns.values):\n",
    "            dict_lower[col] = low\n",
    "            dict_upper[col] = up\n",
    "            dict_med[col] = med\n",
    "\n",
    "\n",
    "        self.features_with_outliers = []\n",
    "        for col in data_cont.columns.values:\n",
    "            if any(data_cont[col]<dict_lower[col]) or any(data_cont[col]>dict_upper[col]):\n",
    "                self.features_with_outliers.append(col)\n",
    "\n",
    "        # for col in data_cont.columns.values:\n",
    "        for col in self.features_with_outliers:\n",
    "            data_cont.loc[data_cont[col]>dict_upper[col],col] = dict_med[col]\n",
    "            data_cont.loc[data_cont[col]<dict_lower[col],col] = dict_med[col]\n",
    "\n",
    "        # Combine transformed features back to original data\n",
    "        df1 = self.dataframe.loc[:,~self.dataframe.columns.isin(list_cont)]\n",
    "        \n",
    "        return pd.merge(df1,data_cont,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d229d0b",
   "metadata": {},
   "source": [
    "## Continuous features vs `pCR`\n",
    "- not much to see through, statistical tests will complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ourm = OutlierRemover(data_cont,list_cont)\n",
    "data_cont_ourm = ourm.transform()\n",
    "# Visualize boxplots\n",
    "fig, axs = plt.subplots(11,10,figsize=(40,30))\n",
    "ax = axs.ravel()\n",
    "df_cont_pcr = pd.merge(data_train.loc[:,['pCR']],data_cont_ourm,left_index=True,right_index=True)\n",
    "for i,j in enumerate(df_cont_pcr.columns.values[1:]):\n",
    "    sns.boxplot(x = df_cont_pcr['pCR'],y = df_cont_pcr.iloc[:,1:].loc[:,j],ax=ax[i],showmeans=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c757d",
   "metadata": {},
   "source": [
    "## ANOVA Test\n",
    "- This will later be incorporated in pipeline for feature selection\n",
    "- Aova test for two groups, is equivalent to t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANOVA test\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "X_anova = data_cont_ourm.iloc[:,1:]\n",
    "y_anova=data_cat.loc[:,'pCR']\n",
    "\n",
    "fstats, pvalues = f_classif(X_anova,y_anova)\n",
    "\n",
    "fselector = SelectKBest(f_classif, k=10)\n",
    "fselector.fit_transform(X_anova,y_anova)\n",
    "\n",
    "print(fselector.get_feature_names_out())\n",
    "print(pvalues[pvalues<0.05])\n",
    "\n",
    "\n",
    "# print(f\"selected features: {X_anova.columns.values[fselector.get_support()]}\")\n",
    "# print(pvalues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0da47c",
   "metadata": {},
   "source": [
    "## Chi-square test for categorical feature selection\n",
    " - Only 3 fetures returned a statistically significant test at 5% significance level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feba963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "X_chi = df_imp.loc[:,list_cat[1:]]\n",
    "y_chi = df_imp.loc[:,['pCR']]\n",
    "chi2_selector = SelectKBest(chi2,k=3)\n",
    "chi2_selector.fit_transform(X=X_chi,y=y_chi)\n",
    "pvalues = chi2_selector.pvalues_\n",
    "\n",
    "print(pvalues[pvalues<0.05])\n",
    "\n",
    "print(chi2_selector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07b282",
   "metadata": {},
   "source": [
    "## Logistic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts floats to intergers for categorical data\n",
    "def to_int(df,list_features):\n",
    "    for f in list_features:\n",
    "        df[f]=df[f].astype('Int64')\n",
    "    return df\n",
    "\n",
    "data_train = to_int(data_train,list_cat)\n",
    "data_train\n",
    "data_test = to_int(data_test,list_cat)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fae239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply robust scaler to image data to scale them and remove outliers\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold, RepeatedStratifiedKFold,RepeatedKFold, cross_val_score,cross_val_predict\n",
    "from sklearn.metrics import balanced_accuracy_score,confusion_matrix,classification_report,roc_curve,auc\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer #For custom transformation functions\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "target = 'pCR'\n",
    "features_to_exlude_in_x = ['ID','pCR','RelapseFreeSurvival']\n",
    "\n",
    "def split_x_y(dataframe,features_to_exlude_in_x,target):\n",
    "    features_to_exlude_in_x.append(target)\n",
    "    y = dataframe.loc[:,target]\n",
    "    X = dataframe.loc[:,~dataframe.columns.isin(features_to_exlude_in_x)]\n",
    "    return X, y\n",
    "\n",
    "X,y = split_x_y(data_train ,features_to_exlude_in_x,target)\n",
    "\n",
    "# Test data\n",
    "X_test, y_test = split_x_y(data_test,features_to_exlude_in_x,target)\n",
    "Xcols = X_test.columns.values\n",
    "\n",
    "# categorical features to select from \n",
    "list_cat[1:]\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "\n",
    "cont_pipeline = Pipeline(steps=[('imputer',imputer),\n",
    "                                ('scaler',RobustScaler()),\n",
    "                                ('kbest_cont',SelectKBest(f_classif,k=9))])\n",
    "\n",
    "cat_pipleline = Pipeline(steps=[('imputer',imputer),\n",
    "                                ('kbest_cat',SelectKBest(chi2,k=4))])\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cont',cont_pipeline,list_cont[1:]),\n",
    "                                              ('cat',cat_pipleline,list_cat[1:])\n",
    "                                            ])\n",
    "\n",
    "regressor = LogisticRegression(max_iter=10_000,class_weight='balanced',random_state=0)\n",
    "clf_lr = Pipeline(steps=[('processor',transformer),\n",
    "                         ('regressor',regressor)])\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__C':[0.01,0.05,1,2,5,10,20]\n",
    "    # 'processor__cont__kbest_cont__k':list(range(1,10))\n",
    "}\n",
    "\n",
    "cv  = RepeatedStratifiedKFold(n_splits=5,n_repeats=5,random_state=0)\n",
    "grid_search = GridSearchCV(estimator=clf_lr,param_grid=param_grid,cv=cv,n_jobs=-1,scoring='balanced_accuracy')\n",
    "\n",
    "grid_search.fit(X,y)\n",
    "clf_lr = grid_search.best_estimator_\n",
    "ba_cv_clf_lr =cross_val_score(clf_lr,X,y,scoring='balanced_accuracy')\n",
    "\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "ba_tst_clf_lr = balanced_accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "\n",
    "\n",
    "print(f\"BA CV: {np.mean(ba_cv_clf_lr):.3f}, cv_sd: {np.std(ba_cv_clf_lr):.3f}, BA Test: {ba_tst_clf_lr:.3f}\")\n",
    "\n",
    "report=classification_report(y_true=y_test,y_pred=y_pred)\n",
    "print(report)\n",
    "clf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing model performance metrics\n",
    "def model_performance(name,cross_validation_score,test_score):\n",
    "    metrics = {'name':name,'ba_cv':np.mean(cross_validation_score),'sd':np.std(cross_validation_score),'ba_test':test_score}\n",
    "    return metrics\n",
    "\n",
    "perfopmance_clf_lr= model_performance('Logistic',ba_cv_clf_lr,ba_tst_clf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424ea4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user function for plotting\n",
    "# def plot_roc_curve(model):\n",
    "#     y_proba = model.predict_proba(X_test)\n",
    "#     fpr, tpr, _ = roc_curve(y_true=y_test,y_score=y_proba[:,1])\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "#     plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title('Receiver Operating Characteristic Curve')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()\n",
    "# plot_roc_curve(clf_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0c110",
   "metadata": {},
   "source": [
    "## Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "# Define the parameters to tune\n",
    "parameters_svm = {'svm__C':[0.01,0.05,1,2,5,20],\n",
    "                  'svm__kernel':['sigmoid']}\n",
    "# Bootstrapping\n",
    "ba_cv_scores_svm = []\n",
    "ba_tst_scores = []\n",
    "for i in range(150):  # Number of bootstrap samples to create\n",
    "    X_sample, y_sample = resample(X, y, replace=True)\n",
    "    \n",
    "    # Define the model\n",
    "    svm = SVC(class_weight='balanced')\n",
    "    clf_svm = Pipeline(steps=[('processor',transformer),\n",
    "                             ('svm',svm)])\n",
    "    \n",
    "    # Define the grid search\n",
    "    cv  = RepeatedStratifiedKFold(n_splits=10,n_repeats=3)\n",
    "    grid_search_svm = GridSearchCV(estimator=clf_svm,param_grid=parameters_svm,cv=cv,n_jobs=-1,scoring='balanced_accuracy')\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search_svm.fit(X_sample, y_sample)\n",
    "    svm = grid_search_svm.best_estimator_\n",
    "    # Calculate the balanced accuracy with cross-validation\n",
    "    ba_cv_svm =cross_val_score(svm,X_sample,y_sample,scoring='balanced_accuracy')\n",
    "    ba_cv_scores_svm.append(np.mean(ba_cv_svm))\n",
    "\n",
    "# Predict on the test set and calculate the balanced accuracy\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "ba_tst_svm = balanced_accuracy_score(y_true=y_test,y_pred=y_pred_svm)\n",
    "\n",
    "\n",
    "# Calculate the average balanced accuracy over all bootstrap samples\n",
    "average_ba_cv_svm = np.mean(ba_cv_svm)\n",
    "# average_ba_tst = np.mean(ba_tst_scores)\n",
    "\n",
    "print(f\"Average BA CV, svm: {average_ba_cv_svm:.3f}, Average BA Test, svm: {ba_tst_svm:.3f}\")\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0904a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Bootstrapping\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "\n",
    "cont_pipeline = Pipeline(steps=[('imputer',imputer),\n",
    "                                ('scaler',RobustScaler()),\n",
    "                                ('kbest_cont',SelectKBest(f_classif))])\n",
    "\n",
    "cat_pipleline = Pipeline(steps=[('imputer',imputer),\n",
    "                                ('kbest_cat',SelectKBest(chi2,k=2))])\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[('cont',cont_pipeline,list_cont[1:]),\n",
    "                                              ('cat',cat_pipleline,list_cat[1:])\n",
    "                                            ])\n",
    "\n",
    "\n",
    "# Define the model\n",
    "svm = SVC(class_weight='balanced',probability=True, random_state=0)\n",
    "clf_svm = Pipeline(steps=[('processor',transformer),\n",
    "                            ('svm',svm)])\n",
    "\n",
    "# Define the grid search\n",
    "# Define the parameters to tune\n",
    "parameters_svm = {'svm__C':[0.01,0.05,1,2,5,20],\n",
    "                  'processor__cont__kbest_cont__k':list(range(1,11)),\n",
    "                  'processor__cat__kbest_cat__k':list(range(1,5)),\n",
    "                  'svm__kernel':['sigmoid']}\n",
    "cv  = RepeatedStratifiedKFold(n_splits=10,n_repeats=3)\n",
    "grid_search_svm = GridSearchCV(estimator=clf_svm,param_grid=parameters_svm,cv=cv,n_jobs=-1,scoring='balanced_accuracy')\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search_svm.fit(X, y)\n",
    "svm = grid_search_svm.best_estimator_\n",
    "# Calculate the balanced accuracy with cross-validation\n",
    "ba_cv_svm =cross_val_score(svm,X,y,scoring='balanced_accuracy')\n",
    "\n",
    "\n",
    "# Predict on the test set and calculate the balanced accuracy\n",
    "y_pred = svm.predict(X_test)\n",
    "ba_tst_svm = balanced_accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "\n",
    "\n",
    "# Calculate the average balanced accuracy over all bootstrap samples\n",
    "average_ba_cv_svm = np.mean(ba_cv_svm)\n",
    "# average_ba_tst = np.mean(ba_tst_scores)\n",
    "\n",
    "print(f\"Average BA CV, svm: {np.mean(ba_cv_svm):.3f}, {np.std(ba_cv_svm):.3f} BA Test, svm: {ba_tst_svm:.3f}\")\n",
    "\n",
    "report=classification_report(y_true=y_test,y_pred=y_pred)\n",
    "print(report)\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfopmance_reg_svm_smote = model_performance('SVM SMOTE',ba_cv_svm,ba_tst_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db3d390",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "- Does not require feature selection, since by its design has inbuit feature selection methods\n",
    "- Thus model is trained with all features included, redundant features will be dropped automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply robust scaler to image data to scale them and remove outliers\n",
    "# With feature selection\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold, RepeatedStratifiedKFold,RepeatedKFold, cross_val_score,cross_val_predict\n",
    "from sklearn.metrics import balanced_accuracy_score,accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "\n",
    "clf_rf = BalancedRandomForestClassifier(200,random_state=0,bootstrap=True,class_weight='balanced_subsample')\n",
    "\n",
    "model_rf = Pipeline(steps=[('imputer',imputer),('classifier',clf_rf)])\n",
    "\n",
    "\n",
    "param_grid = param_grid = {#'classifier__max_features': [2,4,6,8,13],\n",
    "                           'classifier__max_depth': [2,3,4,6]}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_repeats=4,n_splits=10,random_state=0)\n",
    "grid_search = GridSearchCV(estimator=model_rf,param_grid=param_grid,cv=cv,scoring='balanced_accuracy',n_jobs=-1)\n",
    "grid_search.fit(X=X,y=y)\n",
    "bal_random_forest = grid_search.best_estimator_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "ba_cv_rf = cross_val_score(bal_random_forest,X,y,scoring='balanced_accuracy')\n",
    "\n",
    "\n",
    "# Predict and test\n",
    "y_pred = bal_random_forest.predict(X_test)\n",
    "ba_test_rf = balanced_accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "\n",
    "\n",
    "print(f\"BA CV: {np.mean(ba_cv_rf):.3f}, cv_sd: {np.std(ba_cv_rf):.3f}, BA Test: {ba_test_rf:.3f}\")\n",
    "report=classification_report(y_true=y_test,y_pred=y_pred)\n",
    "print(report)\n",
    "bal_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b611ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfopmance_bal_rf = model_performance('Random Forest',ba_cv_rf,ba_test_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3459ec",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple xgboost\n",
    "# Apply robust scaler to image data to scale them and remove outliers\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold, RepeatedStratifiedKFold,RepeatedKFold, cross_val_score,cross_val_predict\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import RobustScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "# Dataframe used is df_imputed, processing steps are embedded in a pipeline\n",
    "target = 'pCR'\n",
    "features_to_exlude_in_x = ['ID','pCR','RelapseFreeSurvival']\n",
    "\n",
    "\n",
    "X,y = split_x_y(data_train,features_to_exlude_in_x,target)\n",
    "\n",
    "\n",
    "X_test, y_test = split_x_y(data_test,features_to_exlude_in_x,target)\n",
    "Xcols = X_test.columns.values\n",
    "\n",
    "imputer = Pipeline(steps=[('knn_imputer',KNNImputer(n_neighbors=1))])\n",
    "cv = RepeatedStratifiedKFold(n_repeats=3,n_splits=10,random_state=0)\n",
    "classifier = XGBClassifier(scale_pos_weight = 0.78/0.22,n_jobs=-1) \n",
    "model = Pipeline(steps=[('imputer',imputer),('classifier',classifier)])\n",
    "\n",
    "\n",
    "# Learning rate controls overfitting, the smaller learning rate means less correction is made to the preceding tree\n",
    "# low value for learning rate  results into more trees\n",
    "# `colsample_bytree` fraction of features to be used to build tree\n",
    "# `gamma` minimum loss reduction to make split. It is pseudo-regularization hyperparameter for complexity control\n",
    "\n",
    "param_grid = param_grid = {#'classifier__n_estimators': [100,200,300],\n",
    "                            'classifier__max_depth': [3,4,5],\n",
    "                            'classifier__learning_rate': [0.1,0.05,0.01],\n",
    "                            'classifier__gamma': [0,0.25,1],\n",
    "                            'classifier__colsample_bytree':[0.05,0.1,0.15]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model,param_grid=param_grid,cv=cv,scoring='balanced_accuracy')\n",
    "grid_search.fit(X,y)\n",
    "xgb = grid_search.best_estimator_\n",
    "ba_xgb_cv = cross_val_score(xgb, X, y, cv=cv, scoring='balanced_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "ba_xgb_test = balanced_accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "\n",
    "print(f\"Cross-validation accuracy: {ba_xgb_cv.mean():.2f}, SD: {ba_xgb_cv.std():.2f}\")\n",
    "print(f\"Test accuracy: {ba_xgb_test:.2f}\")\n",
    "report=classification_report(y_true=y_test,y_pred=y_pred)\n",
    "print(report)\n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98941e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfopmance_xgb = model_performance('XGBoost',ba_xgb_cv,ba_xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_curve(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('random_forest',bal_random_forest),('logit',clf_lr), ('xgb',xgb)],voting='soft')\n",
    "cv = RepeatedStratifiedKFold(random_state=0,n_repeats=3,n_splits=5)\n",
    "ba_cv_voting = cross_val_score(clf_voting, X, y, cv=cv, scoring='balanced_accuracy')\n",
    "clf_voting.fit(X=X,y=y)\n",
    "\n",
    "\n",
    "y_pred = clf_voting.predict(X_test)\n",
    "ba_test_voting = balanced_accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "report=classification_report(y_true=y_test,y_pred=y_pred,output_dict=True)\n",
    "print(f\"CV BA {np.mean(ba_cv_voting):.3f} SD {np.std(ba_cv_voting):.3f} Test BA: {ba_test_voting:.3f}\")\n",
    "# print(report)\n",
    "clf_voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72423f55",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9964bd9",
   "metadata": {},
   "source": [
    "## SAVE BEST MODEL FOR TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c243d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "with open('clf_voting.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_voting, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfopmance_voting = model_performance('Voting Ensemble',ba_cv_voting,ba_test_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755dd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparison of model performance\n",
    "model_name = []\n",
    "cv_score = []\n",
    "sd_cv_score = []\n",
    "test_score = []\n",
    "metrics_list = [perfopmance_clf_lr,perfopmance_bal_rf,perfopmance_xgb,perfopmance_voting]\n",
    "\n",
    "for m in metrics_list:\n",
    "    model_name.append(m['name'])\n",
    "    cv_score.append(m['ba_cv'])\n",
    "    sd_cv_score.append(m['sd'])\n",
    "    test_score.append(m['ba_test'])\n",
    "\n",
    "\n",
    "comparison = pd.DataFrame({'Model':model_name,'Cross Validation':cv_score, 'SD':sd_cv_score, 'Test':test_score})\n",
    "print('Balanced Accuracy')\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4301977",
   "metadata": {},
   "source": [
    "## EXPORT LATEX TABLE FOR REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Model comparison\n",
    "try:\n",
    "    # Create the directory if it doesn't exist\n",
    "    dest_path = './Report_ML'\n",
    "    os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "    # Convert DataFrame to LaTeX\n",
    "    reg_mae = comparison.to_latex(float_format='%.3f',index=False)\n",
    "    print(reg_mae)\n",
    "    # Write the LaTeX string to the file\n",
    "    with open('./Report_ML/clf_ba.tex', 'w') as f:\n",
    "        f.write(reg_mae)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "# Classification report\n",
    "try:\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    indices = df.index.values\n",
    "    indices2 = []\n",
    "    for s in df.index.values:\n",
    "        indices2.append(re.sub(r'\\.0','',s))\n",
    "\n",
    "    df.index = indices2\n",
    "    \n",
    "    # Export to LaTeX\n",
    "    clf_report = df.to_latex(float_format='%.2f')\n",
    "\n",
    "    print(clf_report)\n",
    "    with open('./Report_ML/clf_report.tex', 'w') as f:\n",
    "            f.write(clf_report)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bc5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(report).transpose()\n",
    "indices = df.index.values\n",
    "indices2 = []\n",
    "for s in df.index.values:\n",
    "    indices2.append(re.sub(r'\\.0','',s))\n",
    "\n",
    "indices2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
